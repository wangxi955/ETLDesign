# 前程无忧岗位数据爬取
本项目是一个用于爬取和处理前程无忧网站上的职位信息的工具
补充：！！！本仓库最早设计于21年，现已不维护，主要用于存档，前程无忧网站已改变网页加载方式，原爬虫已不可用（采用了正则表达式获取数据），可修改爬虫为selenium进行爬取
### 功能
- 使用Selenium和Edge浏览器驱动程序爬取51Job网站上的职位信息
- 对爬取的数据进行清洗和处理
- 将处理后的数据保存到CSV文件中
- 生成可视化图表展示职位分布情况

### 安装
- Python 3
- Selenium
- Edge浏览器
- Edge浏览器驱动程序
- pandas
- numpy
- pyecharts
- jieba
- pandas


### 使用说明
1.安装所有依赖项（请参考安装部分）
2.运行craw.py文件，将会爬取51Job网站上的职位信息，并将数据保存到CSV文件中
3.运行deal.py文件，将会对爬取的数据进行清洗和处理，包括薪资转换
4.运行show.py文件，将会生成可视化图表展示职位分布情况
#### 数据处理
deal.py文件中的Datadeal类实现了对爬取数据的处理功能，包括数据过滤和薪资转换。
#### 过滤数据
在filtrate方法中，对爬取的数据进行过滤，只保留包含关键词“大数据”的职位信息。
#### 薪资转换
在salclean方法中，对薪资数据进行转换，将所有薪资统一转换为“千/月”的形式。

### 数据可视化
在show.py文件中，使用pyecharts库生成了职位分布的地理图表。
map_show函数生成了中国各个城市的职位分布地理图表。
map3D_show函数生成了中国各个城市的职位分布3D地图。

### 作者
- 作者：wangxi955
